{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":8130934,"sourceType":"datasetVersion","datasetId":4555568},{"sourceId":8175376,"sourceType":"datasetVersion","datasetId":4839211}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport librosa\nimport numpy as np\nfrom concurrent.futures import ThreadPoolExecutor, as_completed\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-23T19:31:50.588069Z","iopub.execute_input":"2024-08-23T19:31:50.588338Z","iopub.status.idle":"2024-08-23T19:31:52.817065Z","shell.execute_reply.started":"2024-08-23T19:31:50.588303Z","shell.execute_reply":"2024-08-23T19:31:52.816034Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Function to add noise to an audio sample (data augmentation)\ndef add_noise(audio, noise_factor=0.005):\n    noise = np.random.randn(len(audio))\n    augmented_audio = audio + noise_factor * noise\n    return augmented_audio","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:31:52.819120Z","iopub.execute_input":"2024-08-23T19:31:52.819484Z","iopub.status.idle":"2024-08-23T19:31:52.823414Z","shell.execute_reply.started":"2024-08-23T19:31:52.819456Z","shell.execute_reply":"2024-08-23T19:31:52.822828Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load audio files and extract features\ndef extract_features(file_path, augment=False):\n    try:\n        audio, sample_rate = librosa.load(file_path, sr=None)\n        if augment:\n            audio = add_noise(audio)  # Apply noise augmentation\n\n        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n        chroma = librosa.feature.chroma_stft(y=audio, sr=sample_rate)\n        spec_contrast = librosa.feature.spectral_contrast(y=audio, sr=sample_rate)\n\n        features = np.hstack([\n            np.mean(mfccs.T, axis=0),\n            np.mean(chroma.T, axis=0),\n            np.mean(spec_contrast.T, axis=0)\n        ])\n        return features\n    except Exception as e:\n        print(f\"Error processing {file_path}: {e}\")\n        return None","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:31:52.824187Z","iopub.execute_input":"2024-08-23T19:31:52.824414Z","iopub.status.idle":"2024-08-23T19:31:52.832413Z","shell.execute_reply.started":"2024-08-23T19:31:52.824389Z","shell.execute_reply":"2024-08-23T19:31:52.831743Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Function to process files concurrently using ThreadPoolExecutor\ndef process_files_concurrently(file_paths, label, augment=False):\n    features_list = []\n    labels_list = []\n\n    with ThreadPoolExecutor() as executor:\n        futures = {executor.submit(extract_features, file, augment): file for file in file_paths}\n        for future in as_completed(futures):\n            features = future.result()\n            if features is not None:\n                features_list.append(features)\n                labels_list.append(label)\n\n                if augment:\n                    augmented_features = extract_features(futures[future], augment=True)\n                    if augmented_features is not None:\n                        features_list.append(augmented_features)\n                        labels_list.append(label)\n\n    return features_list, labels_list","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:31:52.833289Z","iopub.execute_input":"2024-08-23T19:31:52.833552Z","iopub.status.idle":"2024-08-23T19:31:52.840827Z","shell.execute_reply.started":"2024-08-23T19:31:52.833513Z","shell.execute_reply":"2024-08-23T19:31:52.840110Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Function to process each folder separately\ndef process_folder(folder_name, folder_path, batch_size=50):\n    print(f\"Processing folder: {folder_name}\")\n\n    # Prepare paths for training, testing, and validation\n    train_real_path = os.path.join(folder_path, 'training/real')\n    train_fake_path = os.path.join(folder_path, 'training/fake')\n    test_real_path = os.path.join(folder_path, 'testing/real')\n    test_fake_path = os.path.join(folder_path, 'testing/fake')\n    val_real_path = os.path.join(folder_path, 'validation/real')\n    val_fake_path = os.path.join(folder_path, 'validation/fake')\n\n    # Collect all the file paths\n    train_real_files = [os.path.join(train_real_path, file) for file in os.listdir(train_real_path) if file.endswith('.wav')]\n    train_fake_files = [os.path.join(train_fake_path, file) for file in os.listdir(train_fake_path) if file.endswith('.wav')]\n    test_real_files = [os.path.join(test_real_path, file) for file in os.listdir(test_real_path) if file.endswith('.wav')]\n    test_fake_files = [os.path.join(test_fake_path, file) for file in os.listdir(test_fake_path) if file.endswith('.wav')]\n    val_real_files = [os.path.join(val_real_path, file) for file in os.listdir(val_real_path) if file.endswith('.wav')]\n    val_fake_files = [os.path.join(val_fake_path, file) for file in os.listdir(val_fake_path) if file.endswith('.wav')]\n\n    # Initialize lists for training, testing, and validation features and labels\n    X_train, y_train, X_test, y_test, X_val, y_val = [], [], [], [], [], []\n\n    # Process training files in batches\n    for i in range(0, len(train_real_files), batch_size):\n        batch_real = train_real_files[i:i+batch_size]\n        real_train_features, real_train_labels = process_files_concurrently(batch_real, 0)\n        X_train.extend(real_train_features)\n        y_train.extend(real_train_labels)\n\n        batch_fake = train_fake_files[i:i+batch_size]\n        fake_train_features, fake_train_labels = process_files_concurrently(batch_fake, 1)\n        X_train.extend(fake_train_features)\n        y_train.extend(fake_train_labels)\n\n    # Process testing files\n    test_real_features, test_real_labels = process_files_concurrently(test_real_files, 0)\n    X_test.extend(test_real_features)\n    y_test.extend(test_real_labels)\n\n    test_fake_features, test_fake_labels = process_files_concurrently(test_fake_files, 1)\n    X_test.extend(test_fake_features)\n    y_test.extend(test_fake_labels)\n\n    # Process validation files\n    val_real_features, val_real_labels = process_files_concurrently(val_real_files, 0)\n    X_val.extend(val_real_features)\n    y_val.extend(val_real_labels)\n\n    val_fake_features, val_fake_labels = process_files_concurrently(val_fake_files, 1)\n    X_val.extend(val_fake_features)\n    y_val.extend(val_fake_labels)\n\n    return X_train, y_train, X_test, y_test, X_val, y_val","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:31:52.841762Z","iopub.execute_input":"2024-08-23T19:31:52.841999Z","iopub.status.idle":"2024-08-23T19:31:52.852811Z","shell.execute_reply.started":"2024-08-23T19:31:52.841975Z","shell.execute_reply":"2024-08-23T19:31:52.852095Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define the paths for the different folders\nbase_path = '/kaggle/input/the-fake-or-real-dataset'\nfolders = {\n    'for-2sec': os.path.join(base_path, 'for-2sec/for-2seconds'),\n    'for-norm': os.path.join(base_path, 'for-norm/for-norm'),\n    'for-original': os.path.join(base_path, 'for-original/for-original'),\n    'for-rebec': os.path.join(base_path, 'for-rerec/for-rerecorded')\n}\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:31:52.853690Z","iopub.execute_input":"2024-08-23T19:31:52.853912Z","iopub.status.idle":"2024-08-23T19:31:52.863275Z","shell.execute_reply.started":"2024-08-23T19:31:52.853888Z","shell.execute_reply":"2024-08-23T19:31:52.862505Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Define the paths for the scenefake dataset\nscenefake_path = '/kaggle/input/scenefake'\nscenefake_folders = {\n    'scenefake_train_real': os.path.join(scenefake_path, 'train/real'),\n    'scenefake_train_fake': os.path.join(scenefake_path, 'train/fake'),\n    'scenefake_test_real': os.path.join(scenefake_path, 'test/real'),\n    'scenefake_test_fake': os.path.join(scenefake_path, 'test/fake'),\n    'scenefake_val_real': os.path.join(scenefake_path, 'val/real'),\n    'scenefake_val_fake': os.path.join(scenefake_path, 'val/fake')\n}","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:31:52.864205Z","iopub.execute_input":"2024-08-23T19:31:52.864452Z","iopub.status.idle":"2024-08-23T19:31:52.872976Z","shell.execute_reply.started":"2024-08-23T19:31:52.864427Z","shell.execute_reply":"2024-08-23T19:31:52.872294Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Define the scenefake folder paths\nscenefake_folders = {\n    'scenefake_train_real': '/kaggle/input/scenefake/train/real',\n    'scenefake_train_fake': '/kaggle/input/scenefake/train/fake',\n    'scenefake_test_real': '/kaggle/input/scenefake/eval/real',\n    'scenefake_test_fake': '/kaggle/input/scenefake/eval/fake',\n    'scenefake_val_real': '/kaggle/input/scenefake/dev/real',\n    'scenefake_val_fake': '/kaggle/input/scenefake/dev/fake'\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:31:52.875377Z","iopub.execute_input":"2024-08-23T19:31:52.875918Z","iopub.status.idle":"2024-08-23T19:31:52.879588Z","shell.execute_reply.started":"2024-08-23T19:31:52.875891Z","shell.execute_reply":"2024-08-23T19:31:52.878909Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Function to process the scenefake dataset\ndef process_scenefake_folder(scenefake_folders):\n    X_train, y_train, X_test, y_test, X_val, y_val = [], [], [], [], [], []\n\n    # Define the paths for training, testing, and validation\n    train_real_path = scenefake_folders['scenefake_train_real']\n    train_fake_path = scenefake_folders['scenefake_train_fake']\n    test_real_path = scenefake_folders['scenefake_test_real']\n    test_fake_path = scenefake_folders['scenefake_test_fake']\n    val_real_path = scenefake_folders['scenefake_val_real']\n    val_fake_path = scenefake_folders['scenefake_val_fake']\n\n    # Collect all the file paths\n    train_real_files = [os.path.join(train_real_path, file) for file in os.listdir(train_real_path) if file.endswith('.wav')]\n    train_fake_files = [os.path.join(train_fake_path, file) for file in os.listdir(train_fake_path) if file.endswith('.wav')]\n    test_real_files = [os.path.join(test_real_path, file) for file in os.listdir(test_real_path) if file.endswith('.wav')]\n    test_fake_files = [os.path.join(test_fake_path, file) for file in os.listdir(test_fake_path) if file.endswith('.wav')]\n    val_real_files = [os.path.join(val_real_path, file) for file in os.listdir(val_real_path) if file.endswith('.wav')]\n    val_fake_files = [os.path.join(val_fake_path, file) for file in os.listdir(val_fake_path) if file.endswith('.wav')]\n\n    # Process files and update lists\n    real_train_features, real_train_labels = process_files_concurrently(train_real_files, 0)\n    fake_train_features, fake_train_labels = process_files_concurrently(train_fake_files, 1)\n    X_train.extend(real_train_features)\n    y_train.extend(real_train_labels)\n    X_train.extend(fake_train_features)\n    y_train.extend(fake_train_labels)\n\n    real_test_features, real_test_labels = process_files_concurrently(test_real_files, 0)\n    fake_test_features, fake_test_labels = process_files_concurrently(test_fake_files, 1)\n    X_test.extend(real_test_features)\n    y_test.extend(real_test_labels)\n    X_test.extend(fake_test_features)\n    y_test.extend(fake_test_labels)\n\n    real_val_features, real_val_labels = process_files_concurrently(val_real_files, 0)\n    fake_val_features, fake_val_labels = process_files_concurrently(val_fake_files, 1)\n    X_val.extend(real_val_features)\n    y_val.extend(real_val_labels)\n    X_val.extend(fake_val_features)\n    y_val.extend(fake_val_labels)\n\n    return X_train, y_train, X_test, y_test, X_val, y_val\n\n# Initialize overall data lists for each step\noverall_X_train, overall_y_train, overall_X_test, overall_y_test, overall_X_val, overall_y_val = [], [], [], [], [], []\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:31:52.880513Z","iopub.execute_input":"2024-08-23T19:31:52.880777Z","iopub.status.idle":"2024-08-23T19:31:52.890856Z","shell.execute_reply.started":"2024-08-23T19:31:52.880753Z","shell.execute_reply":"2024-08-23T19:31:52.890159Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Process the scenefake dataset\nprint(\"Processing dataset from: scenefake\")\nX_train, y_train, X_test, y_test, X_val, y_val = process_scenefake_folder(scenefake_folders)\noverall_X_train.extend(X_train)\noverall_y_train.extend(y_train)\noverall_X_test.extend(X_test)\noverall_y_test.extend(y_test)\noverall_X_val.extend(X_val)\noverall_y_val.extend(y_val)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:31:52.891812Z","iopub.execute_input":"2024-08-23T19:31:52.892054Z","iopub.status.idle":"2024-08-23T19:58:53.217126Z","shell.execute_reply.started":"2024-08-23T19:31:52.892029Z","shell.execute_reply":"2024-08-23T19:58:53.215852Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Processing dataset from: scenefake\n","output_type":"stream"}]},{"cell_type":"code","source":"# Process each folder in sequence\nfor folder_name, folder_path in folders.items():\n    print(f\"Processing dataset from: {folder_name}\")\n    \n    X_train, y_train, X_test, y_test, X_val, y_val = process_folder(folder_name, folder_path, batch_size=50)\n    \n    # Update overall data lists\n    overall_X_train.extend(X_train)\n    overall_y_train.extend(y_train)\n    overall_X_test.extend(X_test)\n    overall_y_test.extend(y_test)\n    overall_X_val.extend(X_val)\n    overall_y_val.extend(y_val)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T19:58:53.218620Z","iopub.execute_input":"2024-08-23T19:58:53.219050Z","iopub.status.idle":"2024-08-23T21:05:20.152673Z","shell.execute_reply.started":"2024-08-23T19:58:53.219018Z","shell.execute_reply":"2024-08-23T21:05:20.151622Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Processing dataset from: for-2sec\nProcessing folder: for-2sec\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n  return pitch_tuning(\n","output_type":"stream"},{"name":"stdout","text":"Processing dataset from: for-norm\nProcessing folder: for-norm\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1837\n  warnings.warn(\n/usr/local/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=0\n  warnings.warn(\n/usr/local/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1891\n  warnings.warn(\n/usr/local/lib/python3.10/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1690\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Processing dataset from: for-original\nProcessing folder: for-original\nProcessing dataset from: for-rebec\nProcessing folder: for-rebec\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the Random Forest model on the combined dataset\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(overall_X_train, overall_y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(overall_X_test)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T21:05:20.154047Z","iopub.execute_input":"2024-08-23T21:05:20.154820Z","iopub.status.idle":"2024-08-23T21:07:09.823215Z","shell.execute_reply.started":"2024-08-23T21:05:20.154782Z","shell.execute_reply":"2024-08-23T21:07:09.822021Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Evaluate the model with additional metrics\naccuracy = accuracy_score(overall_y_test, y_pred)\nprecision = precision_score(overall_y_test, y_pred)\nrecall = recall_score(overall_y_test, y_pred)\nf1 = f1_score(overall_y_test, y_pred)\n\nprint(f\"Overall Results:\")\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1-score: {f1:.4f}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-08-23T21:07:09.824452Z","iopub.execute_input":"2024-08-23T21:07:09.824761Z","iopub.status.idle":"2024-08-23T21:07:09.889579Z","shell.execute_reply.started":"2024-08-23T21:07:09.824731Z","shell.execute_reply":"2024-08-23T21:07:09.888730Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Overall Results:\nAccuracy: 0.7721\nPrecision: 0.9167\nRecall: 0.7571\nF1-score: 0.8293\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Function to predict if a new audio file is fake or real\ndef predict_fake_audio(file_path):\n    features = extract_features(file_path)\n    if features is None:\n        return \"Error in processing audio file.\"\n\n    prediction = model.predict([features])[0]\n    if prediction == 0:\n        return \"Real audio\"\n    else:\n        return \"Fake audio\"","metadata":{"execution":{"iopub.status.busy":"2024-08-23T21:07:09.890677Z","iopub.execute_input":"2024-08-23T21:07:09.890939Z","iopub.status.idle":"2024-08-23T21:07:09.895749Z","shell.execute_reply.started":"2024-08-23T21:07:09.890914Z","shell.execute_reply":"2024-08-23T21:07:09.894846Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T21:07:09.896909Z","iopub.execute_input":"2024-08-23T21:07:09.897198Z","iopub.status.idle":"2024-08-23T21:07:23.056609Z","shell.execute_reply.started":"2024-08-23T21:07:09.897172Z","shell.execute_reply":"2024-08-23T21:07:23.055547Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1724447235.678923      13 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD0823 21:07:15.687866938      13 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD0823 21:07:15.687887611      13 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD0823 21:07:15.687891139      13 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD0823 21:07:15.687893795      13 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD0823 21:07:15.687896311      13 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD0823 21:07:15.687898840      13 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD0823 21:07:15.687901490      13 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD0823 21:07:15.687903910      13 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD0823 21:07:15.687906281      13 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD0823 21:07:15.687908665      13 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD0823 21:07:15.687911088      13 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD0823 21:07:15.687913590      13 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD0823 21:07:15.687915954      13 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD0823 21:07:15.687918329      13 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD0823 21:07:15.687920674      13 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD0823 21:07:15.687923050      13 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD0823 21:07:15.687925566      13 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD0823 21:07:15.687927968      13 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD0823 21:07:15.687930344      13 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD0823 21:07:15.687932774      13 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD0823 21:07:15.687935162      13 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD0823 21:07:15.687937563      13 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD0823 21:07:15.687940023      13 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD0823 21:07:15.687942619      13 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD0823 21:07:15.687944958      13 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD0823 21:07:15.687947297      13 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD0823 21:07:15.687949732      13 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD0823 21:07:15.687952118      13 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD0823 21:07:15.687954625      13 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD0823 21:07:15.687958084      13 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD0823 21:07:15.687960641      13 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD0823 21:07:15.687963054      13 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD0823 21:07:15.687965637      13 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD0823 21:07:15.687968023      13 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD0823 21:07:15.687970397      13 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD0823 21:07:15.687972744      13 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD0823 21:07:15.687975054      13 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD0823 21:07:15.687977399      13 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD0823 21:07:15.687979830      13 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD0823 21:07:15.687982198      13 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD0823 21:07:15.687984534      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD0823 21:07:15.687986849      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD0823 21:07:15.687989214      13 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD0823 21:07:15.687991638      13 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD0823 21:07:15.687994058      13 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI0823 21:07:15.688168507      13 ev_epoll1_linux.cc:123]               grpc epoll fd: 59\nD0823 21:07:15.688181475      13 ev_posix.cc:113]                      Using polling engine: epoll1\nD0823 21:07:15.699002077      13 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0823 21:07:15.699014441      13 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0823 21:07:15.699022608      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0823 21:07:15.699026049      13 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0823 21:07:15.699029529      13 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0823 21:07:15.699043631      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD0823 21:07:15.699070764      13 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0823 21:07:15.699082760      13 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD0823 21:07:15.699098786      13 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0823 21:07:15.699122129      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0823 21:07:15.699129429      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0823 21:07:15.699132402      13 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0823 21:07:15.699136181      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0823 21:07:15.699139260      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0823 21:07:15.699142177      13 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0823 21:07:15.699145264      13 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD0823 21:07:15.699173514      13 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI0823 21:07:15.700268437      13 ev_epoll1_linux.cc:359]               grpc epoll fd: 61\nI0823 21:07:15.701375661      13 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI0823 21:07:15.704961468   70385 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI0823 21:07:15.705014038   70385 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0823 21:07:15.711845044      13 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-08-23T21:07:15.711828171+00:00\", grpc_status:2}\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\n# Assuming the input shape is (13, 1, 1) as per the error\ninput_shape = (13, 1, 1)\n\n# Create a simple CNN model with compatible kernel sizes\nmodel = models.Sequential([\n    layers.Conv2D(32, (1, 1), activation='relu', input_shape=input_shape),  # Adjust kernel size\n    layers.MaxPooling2D((1, 1)),  # Adjust pooling size\n    layers.Conv2D(64, (1, 1), activation='relu'),  # Adjust kernel size\n    layers.MaxPooling2D((1, 1)),  # Adjust pooling size\n    layers.Conv2D(64, (1, 1), activation='relu'),  # Adjust kernel size\n    layers.Flatten(),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(10, activation='softmax')  # Adjust output according to your classes\n])\n\n# Compile the model\nmodel.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\n# Print the model summary\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T21:07:23.058091Z","iopub.execute_input":"2024-08-23T21:07:23.058608Z","iopub.status.idle":"2024-08-23T21:07:27.130203Z","shell.execute_reply.started":"2024-08-23T21:07:23.058576Z","shell.execute_reply":"2024-08-23T21:07:27.129260Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1724447247.028121      13 service.cc:145] XLA service 0x5bcf4191d7f0 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1724447247.028179      13 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1724447247.028184      13 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1724447247.028187      13 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1724447247.028189      13 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1724447247.028192      13 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1724447247.028195      13 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1724447247.028197      13 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1724447247.028201      13 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │            \u001b[38;5;34m64\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │         \u001b[38;5;34m2,112\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │         \u001b[38;5;34m4,160\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m832\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m53,312\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">53,312</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,298\u001b[0m (235.54 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,298</span> (235.54 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,298\u001b[0m (235.54 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,298</span> (235.54 KB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"model.save('/kaggle/working/DeepfakeAudio2.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T21:07:27.131295Z","iopub.execute_input":"2024-08-23T21:07:27.131584Z","iopub.status.idle":"2024-08-23T21:07:27.161405Z","shell.execute_reply.started":"2024-08-23T21:07:27.131555Z","shell.execute_reply":"2024-08-23T21:07:27.160578Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"}]},{"cell_type":"code","source":"import joblib\n\n# Save the RandomForest model\njoblib.dump(model, 'deepfake_audio_rf_model.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T21:07:27.162705Z","iopub.execute_input":"2024-08-23T21:07:27.162994Z","iopub.status.idle":"2024-08-23T21:07:27.192712Z","shell.execute_reply.started":"2024-08-23T21:07:27.162967Z","shell.execute_reply":"2024-08-23T21:07:27.191853Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"['deepfake_audio_rf_model.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"import joblib\n\n# Load the RandomForest model\nmodel = joblib.load('deepfake_audio_rf_model.pkl')\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T21:07:27.193715Z","iopub.execute_input":"2024-08-23T21:07:27.194006Z","iopub.status.idle":"2024-08-23T21:07:27.304202Z","shell.execute_reply.started":"2024-08-23T21:07:27.193978Z","shell.execute_reply":"2024-08-23T21:07:27.303387Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/keras/src/saving/saving_lib.py:713: UserWarning: Skipping variable loading for optimizer 'rmsprop', because it has 12 variables whereas the saved optimizer has 2 variables. \n  saveable.load_own_variables(weights_store.get(inner_path))\n","output_type":"stream"}]},{"cell_type":"code","source":"import joblib\n\n# Define the path for saving the model\nmodel_path = '/kaggle/working/deepfake_audio_rf_model.pkl'\n\n# Save the RandomForest model\njoblib.dump(model, model_path)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T21:07:27.305146Z","iopub.execute_input":"2024-08-23T21:07:27.305407Z","iopub.status.idle":"2024-08-23T21:07:27.333057Z","shell.execute_reply.started":"2024-08-23T21:07:27.305380Z","shell.execute_reply":"2024-08-23T21:07:27.332314Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/deepfake_audio_rf_model.pkl']"},"metadata":{}}]},{"cell_type":"code","source":"# Save the model\nmodel.save('/kaggle/working/DeepfakeDetection.h5')\n\nprint(\"Model saved as 'DeepfakeAudio.h5'\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T21:07:27.333956Z","iopub.execute_input":"2024-08-23T21:07:27.334199Z","iopub.status.idle":"2024-08-23T21:07:27.354414Z","shell.execute_reply.started":"2024-08-23T21:07:27.334173Z","shell.execute_reply":"2024-08-23T21:07:27.353682Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stderr","text":"WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n","output_type":"stream"},{"name":"stdout","text":"Model saved as 'DeepfakeAudio.h5'\n","output_type":"stream"}]},{"cell_type":"code","source":"# Example usage:\nnew_audio_file = input(\"Enter the path to the audio file you want to check: \")\n\n# Ensure that the file exists\nif os.path.exists(new_audio_file):\n    result = predict_fake_audio(new_audio_file)\n    print(f\"The prediction for the audio file is: {result}\")\nelse:\n    print(\"The specified file does not exist. Please check the path and try again.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-08-23T21:16:21.160450Z","iopub.execute_input":"2024-08-23T21:16:21.161259Z","iopub.status.idle":"2024-08-23T21:16:27.535459Z","shell.execute_reply.started":"2024-08-23T21:16:21.161224Z","shell.execute_reply":"2024-08-23T21:16:27.534112Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdin","text":"Enter the path to the audio file you want to check:  /kaggle/input/the-fake-or-real-dataset/for-2sec/for-2seconds/training/fake/file10007.mp3.wav_16k.wav_norm.wav_mono.wav_silence.wav_2sec.wav\n"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[23], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Ensure that the file exists\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(new_audio_file):\n\u001b[0;32m----> 6\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_fake_audio\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_audio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe prediction for the audio file is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","Cell \u001b[0;32mIn[14], line 7\u001b[0m, in \u001b[0;36mpredict_fake_audio\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError in processing audio file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReal audio\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/usr/local/lib/python3.10/site-packages/keras/src/models/functional.py:244\u001b[0m, in \u001b[0;36mFunctional._adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    242\u001b[0m             adjusted\u001b[38;5;241m.\u001b[39mappend(ops\u001b[38;5;241m.\u001b[39mexpand_dims(x, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m    243\u001b[0m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid input shape for input \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Expected shape \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but input has incompatible shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m     )\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# Add back metadata.\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(flat_inputs)):\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32,), dtype=float32). Expected shape (None, 13, 1, 1), but input has incompatible shape (32,)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=('tf.Tensor(shape=(32,), dtype=float32)',)\n  • training=False\n  • mask=('None',)"],"ename":"ValueError","evalue":"Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32,), dtype=float32). Expected shape (None, 13, 1, 1), but input has incompatible shape (32,)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=('tf.Tensor(shape=(32,), dtype=float32)',)\n  • training=False\n  • mask=('None',)","output_type":"error"}]}]}